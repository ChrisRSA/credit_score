{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "This notebook is where I have performed all my modelling tasks and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/06 15:34:11 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "## all necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import mlflow\n",
    "import lightgbm as lgbm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import optuna\n",
    "import pickle\n",
    "\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "mlflow.set_experiment(\"credit_score\")\n",
    "mlflow.sklearn.autolog()\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>has_payment_note</th>\n",
       "      <th>payment_note_amount</th>\n",
       "      <th>years_data</th>\n",
       "      <th>revenue</th>\n",
       "      <th>revenue-1</th>\n",
       "      <th>revenue-2</th>\n",
       "      <th>revenue-3</th>\n",
       "      <th>revenue-4</th>\n",
       "      <th>net_sales</th>\n",
       "      <th>...</th>\n",
       "      <th>profit_margin-1</th>\n",
       "      <th>profit_margin-2</th>\n",
       "      <th>profit_margin-3</th>\n",
       "      <th>profit_margin-4</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>cash_ratio-1</th>\n",
       "      <th>cash_ratio-2</th>\n",
       "      <th>cash_ratio-3</th>\n",
       "      <th>cash_ratio-4</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6487.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5677</td>\n",
       "      <td>8673.0</td>\n",
       "      <td>8532.0</td>\n",
       "      <td>7825.0</td>\n",
       "      <td>5385.0</td>\n",
       "      <td>5677</td>\n",
       "      <td>...</td>\n",
       "      <td>13.6</td>\n",
       "      <td>10.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>395.5</td>\n",
       "      <td>232.4</td>\n",
       "      <td>184.7</td>\n",
       "      <td>236.4</td>\n",
       "      <td>148.1</td>\n",
       "      <td>AAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10617</td>\n",
       "      <td>8266.0</td>\n",
       "      <td>9713.0</td>\n",
       "      <td>9428.0</td>\n",
       "      <td>7394.0</td>\n",
       "      <td>10506</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>15.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>16.8</td>\n",
       "      <td>229.0</td>\n",
       "      <td>280.7</td>\n",
       "      <td>296.1</td>\n",
       "      <td>234.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>22629</td>\n",
       "      <td>20668.0</td>\n",
       "      <td>24591.0</td>\n",
       "      <td>23754.0</td>\n",
       "      <td>23656.0</td>\n",
       "      <td>22619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>97.8</td>\n",
       "      <td>89.2</td>\n",
       "      <td>82.2</td>\n",
       "      <td>72.4</td>\n",
       "      <td>92.9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>85539.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10221</td>\n",
       "      <td>8358.0</td>\n",
       "      <td>5865.0</td>\n",
       "      <td>4038.0</td>\n",
       "      <td>5128.0</td>\n",
       "      <td>10216</td>\n",
       "      <td>...</td>\n",
       "      <td>14.6</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>9.7</td>\n",
       "      <td>159.9</td>\n",
       "      <td>183.1</td>\n",
       "      <td>112.5</td>\n",
       "      <td>215.5</td>\n",
       "      <td>134.3</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_id  has_payment_note  payment_note_amount  years_data  revenue  \\\n",
       "0           1                 1               6487.0           5     5677   \n",
       "1           2                 0                  0.0           5    10617   \n",
       "2           3                 0                  0.0           1     7201   \n",
       "3           4                 0                  0.0           5    22629   \n",
       "4           5                 1              85539.0           5    10221   \n",
       "\n",
       "   revenue-1  revenue-2  revenue-3  revenue-4  net_sales  ...  \\\n",
       "0     8673.0     8532.0     7825.0     5385.0       5677  ...   \n",
       "1     8266.0     9713.0     9428.0     7394.0      10506  ...   \n",
       "2        0.0        0.0        0.0        0.0       7201  ...   \n",
       "3    20668.0    24591.0    23754.0    23656.0      22619  ...   \n",
       "4     8358.0     5865.0     4038.0     5128.0      10216  ...   \n",
       "\n",
       "   profit_margin-1  profit_margin-2  profit_margin-3  profit_margin-4  \\\n",
       "0             13.6             10.3             16.8             -5.4   \n",
       "1              9.1             15.9             23.1             16.8   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.2              2.9              0.1              1.9   \n",
       "4             14.6             -0.4             -0.6              9.7   \n",
       "\n",
       "   cash_ratio  cash_ratio-1  cash_ratio-2  cash_ratio-3  cash_ratio-4  Rating  \n",
       "0       395.5         232.4         184.7         236.4         148.1     AAA  \n",
       "1       229.0         280.7         296.1         234.0         213.0      AA  \n",
       "2       128.1           0.0           0.0           0.0           0.0      AA  \n",
       "3        97.8          89.2          82.2          72.4          92.9       A  \n",
       "4       159.9         183.1         112.5         215.5         134.3      AA  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/cleaned/train.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'AA', 'AAA', 'B', 'C'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## endcode the 5 training labels\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(df['Rating'])\n",
    "np.save('../models/classes.npy', le.classes_)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels = le.transform(df['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAA', 'AA', 'AA', ..., 'AA', 'AA', 'AA'], dtype=object)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test undoing the encoding\n",
    "le.inverse_transform(encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_payment_note</th>\n",
       "      <th>payment_note_amount</th>\n",
       "      <th>years_data</th>\n",
       "      <th>revenue</th>\n",
       "      <th>revenue-1</th>\n",
       "      <th>revenue-2</th>\n",
       "      <th>revenue-3</th>\n",
       "      <th>revenue-4</th>\n",
       "      <th>net_sales</th>\n",
       "      <th>net_sales-1</th>\n",
       "      <th>...</th>\n",
       "      <th>profit_margin-1</th>\n",
       "      <th>profit_margin-2</th>\n",
       "      <th>profit_margin-3</th>\n",
       "      <th>profit_margin-4</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>cash_ratio-1</th>\n",
       "      <th>cash_ratio-2</th>\n",
       "      <th>cash_ratio-3</th>\n",
       "      <th>cash_ratio-4</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6487.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5677</td>\n",
       "      <td>8673.0</td>\n",
       "      <td>8532.0</td>\n",
       "      <td>7825.0</td>\n",
       "      <td>5385.0</td>\n",
       "      <td>5677</td>\n",
       "      <td>8663.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.6</td>\n",
       "      <td>10.3</td>\n",
       "      <td>16.8</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>395.5</td>\n",
       "      <td>232.4</td>\n",
       "      <td>184.7</td>\n",
       "      <td>236.4</td>\n",
       "      <td>148.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10617</td>\n",
       "      <td>8266.0</td>\n",
       "      <td>9713.0</td>\n",
       "      <td>9428.0</td>\n",
       "      <td>7394.0</td>\n",
       "      <td>10506</td>\n",
       "      <td>8254.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>15.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>16.8</td>\n",
       "      <td>229.0</td>\n",
       "      <td>280.7</td>\n",
       "      <td>296.1</td>\n",
       "      <td>234.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>22629</td>\n",
       "      <td>20668.0</td>\n",
       "      <td>24591.0</td>\n",
       "      <td>23754.0</td>\n",
       "      <td>23656.0</td>\n",
       "      <td>22619</td>\n",
       "      <td>20667.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>97.8</td>\n",
       "      <td>89.2</td>\n",
       "      <td>82.2</td>\n",
       "      <td>72.4</td>\n",
       "      <td>92.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>85539.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10221</td>\n",
       "      <td>8358.0</td>\n",
       "      <td>5865.0</td>\n",
       "      <td>4038.0</td>\n",
       "      <td>5128.0</td>\n",
       "      <td>10216</td>\n",
       "      <td>8358.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.6</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>9.7</td>\n",
       "      <td>159.9</td>\n",
       "      <td>183.1</td>\n",
       "      <td>112.5</td>\n",
       "      <td>215.5</td>\n",
       "      <td>134.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   has_payment_note  payment_note_amount  years_data  revenue  revenue-1  \\\n",
       "0                 1               6487.0           5     5677     8673.0   \n",
       "1                 0                  0.0           5    10617     8266.0   \n",
       "2                 0                  0.0           1     7201        0.0   \n",
       "3                 0                  0.0           5    22629    20668.0   \n",
       "4                 1              85539.0           5    10221     8358.0   \n",
       "\n",
       "   revenue-2  revenue-3  revenue-4  net_sales  net_sales-1  ...  \\\n",
       "0     8532.0     7825.0     5385.0       5677       8663.0  ...   \n",
       "1     9713.0     9428.0     7394.0      10506       8254.0  ...   \n",
       "2        0.0        0.0        0.0       7201          0.0  ...   \n",
       "3    24591.0    23754.0    23656.0      22619      20667.0  ...   \n",
       "4     5865.0     4038.0     5128.0      10216       8358.0  ...   \n",
       "\n",
       "   profit_margin-1  profit_margin-2  profit_margin-3  profit_margin-4  \\\n",
       "0             13.6             10.3             16.8             -5.4   \n",
       "1              9.1             15.9             23.1             16.8   \n",
       "2              0.0              0.0              0.0              0.0   \n",
       "3              0.2              2.9              0.1              1.9   \n",
       "4             14.6             -0.4             -0.6              9.7   \n",
       "\n",
       "   cash_ratio  cash_ratio-1  cash_ratio-2  cash_ratio-3  cash_ratio-4  Rating  \n",
       "0       395.5         232.4         184.7         236.4         148.1       2  \n",
       "1       229.0         280.7         296.1         234.0         213.0       1  \n",
       "2       128.1           0.0           0.0           0.0           0.0       1  \n",
       "3        97.8          89.2          82.2          72.4          92.9       0  \n",
       "4       159.9         183.1         112.5         215.5         134.3       1  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'] = encoded_labels\n",
    "df.drop('company_id', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapid Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/06 15:34:24 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '79c210b3d12b4adb80df263beaa9c6de', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2021/12/06 15:34:49 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: [Errno 30] Read-only file system: '/mnt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.01      0.03       648\n",
      "           1       0.46      0.93      0.61      1318\n",
      "           2       0.74      0.38      0.51       845\n",
      "           3       0.50      0.00      0.01       299\n",
      "           4       0.51      0.41      0.46       180\n",
      "\n",
      "    accuracy                           0.50      3290\n",
      "   macro avg       0.50      0.35      0.32      3290\n",
      "weighted avg       0.51      0.50      0.41      3290\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/06 15:34:54 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'afee5d221c86475c85a280c48e67e81f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2021/12/06 15:34:55 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: [Errno 30] Read-only file system: '/mnt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       648\n",
      "           1       0.66      0.69      0.68      1318\n",
      "           2       0.68      0.65      0.67       845\n",
      "           3       0.59      0.53      0.56       299\n",
      "           4       0.63      0.64      0.64       180\n",
      "\n",
      "    accuracy                           0.65      3290\n",
      "   macro avg       0.63      0.62      0.63      3290\n",
      "weighted avg       0.65      0.65      0.65      3290\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/06 15:34:56 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '86202488c29445d7b1c69fd86369318f', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2021/12/06 15:34:57 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: [Errno 30] Read-only file system: '/mnt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.40      0.44       648\n",
      "           1       0.57      0.78      0.66      1318\n",
      "           2       0.65      0.53      0.59       845\n",
      "           3       0.66      0.27      0.39       299\n",
      "           4       0.69      0.53      0.60       180\n",
      "\n",
      "    accuracy                           0.58      3290\n",
      "   macro avg       0.61      0.50      0.53      3290\n",
      "weighted avg       0.59      0.58      0.57      3290\n",
      "\n",
      "LGBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71       648\n",
      "           1       0.75      0.82      0.78      1318\n",
      "           2       0.79      0.77      0.78       845\n",
      "           3       0.77      0.62      0.69       299\n",
      "           4       0.81      0.71      0.76       180\n",
      "\n",
      "    accuracy                           0.76      3290\n",
      "   macro avg       0.77      0.72      0.74      3290\n",
      "weighted avg       0.76      0.76      0.76      3290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rapidly test a group of models with 3 fold cross validation\n",
    "dfs = []\n",
    "models = [\n",
    "    ('SVC', SVC()), \n",
    "    ('DT', DecisionTreeClassifier()),\n",
    "    ('LOG', LogisticRegression()),\n",
    "    ('LGBM', lgbm.LGBMClassifier())]\n",
    "results = []\n",
    "names = []\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "for name, model in models:\n",
    "    skfolds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    with mlflow.start_run() as run:\n",
    "        cv_results = cross_validate(model, X_train, y_train, cv=skfolds, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    clf = model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(name)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    names.append(name)\n",
    "    this_df = pd.DataFrame(cv_results)\n",
    "    this_df['model'] = name\n",
    "    dfs.append(this_df)\n",
    "    final = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>2.127338</td>\n",
       "      <td>0.036013</td>\n",
       "      <td>0.745765</td>\n",
       "      <td>0.746466</td>\n",
       "      <td>0.694849</td>\n",
       "      <td>0.717059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT</th>\n",
       "      <td>0.309155</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.642168</td>\n",
       "      <td>0.607341</td>\n",
       "      <td>0.604957</td>\n",
       "      <td>0.605851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOG</th>\n",
       "      <td>0.318079</td>\n",
       "      <td>0.012320</td>\n",
       "      <td>0.577925</td>\n",
       "      <td>0.566147</td>\n",
       "      <td>0.454487</td>\n",
       "      <td>0.484343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>1.961555</td>\n",
       "      <td>2.165289</td>\n",
       "      <td>0.505343</td>\n",
       "      <td>0.373216</td>\n",
       "      <td>0.323239</td>\n",
       "      <td>0.301150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "model                                                              \n",
       "LGBM   2.127338    0.036013       0.745765              0.746466   \n",
       "DT     0.309155    0.009129       0.642168              0.607341   \n",
       "LOG    0.318079    0.012320       0.577925              0.566147   \n",
       "SVC    1.961555    2.165289       0.505343              0.373216   \n",
       "\n",
       "       test_recall_macro  test_f1_macro  \n",
       "model                                    \n",
       "LGBM            0.694849       0.717059  \n",
       "DT              0.604957       0.605851  \n",
       "LOG             0.454487       0.484343  \n",
       "SVC             0.323239       0.301150  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare mean results across the three folds\n",
    "final = final.groupby('model').mean().sort_values(by='test_accuracy', ascending = False)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  fit\\_time &  score\\_time &  test\\_accuracy &  test\\_precision\\_macro &  test\\_recall\\_macro &  test\\_f1\\_macro \\\\\n",
      "model &           &             &                &                       &                    &                \\\\\n",
      "\\midrule\n",
      "LGBM  &  2.127338 &    0.036013 &       0.745765 &              0.746466 &           0.694849 &       0.717059 \\\\\n",
      "DT    &  0.309155 &    0.009129 &       0.642168 &              0.607341 &           0.604957 &       0.605851 \\\\\n",
      "LOG   &  0.318079 &    0.012320 &       0.577925 &              0.566147 &           0.454487 &       0.484343 \\\\\n",
      "SVC   &  1.961555 &    2.165289 &       0.505343 &              0.373216 &           0.323239 &       0.301150 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(final.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/ipykernel_4986/3288181742.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mthe_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcellText\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolLabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#https://stackoverflow.com/questions/4042192/reduce-left-and-right-margins-in-matplotlib-plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/22seven/lib/python3.8/site-packages/matplotlib/table.py\u001b[0m in \u001b[0;36mtable\u001b[0;34m(ax, cellText, cellColours, cellLoc, colWidths, rowLabels, rowColours, rowLoc, colLabels, colColours, colLoc, loc, bbox, edges, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m             table.add_cell(row + offset, col,\n\u001b[0m\u001b[1;32m    799\u001b[0m                            \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolWidths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                            \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcellText\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/22seven/lib/python3.8/site-packages/matplotlib/table.py\u001b[0m in \u001b[0;36madd_cell\u001b[0;34m(self, row, col, *args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \"\"\"\n\u001b[1;32m    336\u001b[0m         \u001b[0mxy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisible_edges\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/22seven/lib/python3.8/site-packages/matplotlib/table.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xy, width, height, edgecolor, facecolor, fill, text, loc, fontproperties, visible_edges)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Call base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         super().__init__(xy, width=width, height=height, fill=fill,\n\u001b[0m\u001b[1;32m     89\u001b[0m                          edgecolor=edgecolor, facecolor=facecolor)\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_on\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/22seven/lib/python3.8/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xy, width, height, angle, **kwargs)\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPatch_kwdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \"\"\"\n\u001b[0;32m--> 752\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/22seven/lib/python3.8/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, edgecolor, facecolor, color, linewidth, linestyle, antialiased, hatch, fill, capstyle, joinstyle, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_antialiased\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mantialiased\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_capstyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_joinstyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoinstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/22seven/lib/python3.8/site-packages/matplotlib/patches.py\u001b[0m in \u001b[0;36mset_capstyle\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCapStyle\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCapStyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \"\"\"\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCapStyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/22seven/lib/python3.8/enum.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# simple value lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;31m# otherwise, functional API: we're creating a new Enum type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         return cls._create_(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAADnCAYAAAA5Hh/PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEg0lEQVR4nO3WMQEAIAzAMMC/56GAmx6Jgp7dM7MAAKDo/A4AAIAXswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkmVUAALLMKgAAWWYVAIAsswoAQJZZBQAgy6wCAJBlVgEAyDKrAABkXYAHBMvuQC2HAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax =plt.subplots(figsize=(12,4))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "the_table = ax.table(cellText=final.values,colLabels=final.columns,loc='center')\n",
    "\n",
    "#https://stackoverflow.com/questions/4042192/reduce-left-and-right-margins-in-matplotlib-plot\n",
    "#pp = PdfPages(\"foo.pdf\")\n",
    "#pp.savefig(fig, bbox_inches='tight')\n",
    "#pp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup a lightgbm model\n",
    "clf = lgbm.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model accuracy score: 0.7544\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9878\n",
      "Test set score: 0.7544\n"
     ]
    }
   ],
   "source": [
    "print('Training set score: {:.4f}'.format(clf.score(X_train, y_train)))\n",
    "print('Test set score: {:.4f}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[ 456  142   15   28    7]\n",
      " [  76 1079  150    9    4]\n",
      " [   7  186  651    1    0]\n",
      " [  67   25    3  185   19]\n",
      " [  26    8    1   17  128]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_decoded, y_pred_decoded)\n",
    "print('Confusion matrix\\n\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "cm_matrix = pd.DataFrame(data=cm)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.savefig('../images/confusion_matrix.png', facecolor='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.70      0.71       648\n",
      "           1       0.75      0.82      0.78      1318\n",
      "           2       0.79      0.77      0.78       845\n",
      "           3       0.77      0.62      0.69       299\n",
      "           4       0.81      0.71      0.76       180\n",
      "\n",
      "    accuracy                           0.76      3290\n",
      "   macro avg       0.77      0.72      0.74      3290\n",
      "weighted avg       0.76      0.76      0.76      3290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## these are good metrics on the test set\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## get feature importances\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns)), columns=['Value','Feature'])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False)[:10])\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/lgbm_importances.png', facecolor='w')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup objective grid for tuning\n",
    "def objective(trial, X, y):\n",
    "    param_grid = {\n",
    "        #\"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"dart\"]),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        model = lgbm.LGBMClassifier(objective=\"multiclass\", class_weight='balanced', **param_grid)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            eval_metric=\"multi_logloss\",\n",
    "            early_stopping_rounds=100,\n",
    "            callbacks=[\n",
    "                LightGBMPruningCallback(trial, metric=\"multi_logloss\")\n",
    "            ],  # Add a pruning callback\n",
    "        )\n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_scores[idx] = log_loss(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:10,496]\u001b[0m A new study created in memory with name: LGBM Classifier\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8600\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.68455152096629, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.68455152096629\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8600\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.68455152096629, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.68455152096629\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8600\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.68455152096629, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.68455152096629\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8600\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.68455152096629, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.68455152096629\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:11,274]\u001b[0m Trial 0 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.21764491652150908, 'num_leaves': 700, 'max_depth': 8, 'min_data_in_leaf': 8600, 'lambda_l1': 20, 'lambda_l2': 35, 'min_gain_to_split': 13.68455152096629, 'bagging_fraction': 0.2, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 0 with value: 1.609437911221773.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8600\n",
      "[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\n",
      "[LightGBM] [Warning] min_gain_to_split is set=13.68455152096629, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.68455152096629\n",
      "[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.604745970361854, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.604745970361854\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.604745970361854, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.604745970361854\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.604745970361854, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.604745970361854\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.604745970361854, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.604745970361854\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000\n",
      "[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.604745970361854, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.604745970361854\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:11,938]\u001b[0m Trial 1 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.15621191342684412, 'num_leaves': 1440, 'max_depth': 10, 'min_data_in_leaf': 8000, 'lambda_l1': 5, 'lambda_l2': 40, 'min_gain_to_split': 14.604745970361854, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 0 with value: 1.609437911221773.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9300\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.633426855067295, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.633426855067295\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9300\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.633426855067295, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.633426855067295\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9300\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.633426855067295, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.633426855067295\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9300\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.633426855067295, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.633426855067295\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:12,597]\u001b[0m Trial 2 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.06470731046892043, 'num_leaves': 980, 'max_depth': 12, 'min_data_in_leaf': 9300, 'lambda_l1': 65, 'lambda_l2': 60, 'min_gain_to_split': 4.633426855067295, 'bagging_fraction': 0.5, 'bagging_freq': 1, 'feature_fraction': 0.7}. Best is trial 0 with value: 1.609437911221773.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9300\n",
      "[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\n",
      "[LightGBM] [Warning] min_gain_to_split is set=4.633426855067295, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.633426855067295\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.293082483958717, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.293082483958717\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.293082483958717, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.293082483958717\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.293082483958717, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.293082483958717\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.293082483958717, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.293082483958717\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700\n",
      "[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.293082483958717, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.293082483958717\n",
      "[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:13,281]\u001b[0m Trial 3 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.16518902805236982, 'num_leaves': 660, 'max_depth': 12, 'min_data_in_leaf': 4700, 'lambda_l1': 95, 'lambda_l2': 45, 'min_gain_to_split': 9.293082483958717, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 0 with value: 1.609437911221773.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10000\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.585777363287365, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.585777363287365\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10000\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.585777363287365, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.585777363287365\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10000\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.585777363287365, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.585777363287365\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10000\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.585777363287365, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.585777363287365\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:13,983]\u001b[0m Trial 4 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04201080585437659, 'num_leaves': 1020, 'max_depth': 5, 'min_data_in_leaf': 10000, 'lambda_l1': 65, 'lambda_l2': 5, 'min_gain_to_split': 6.585777363287365, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.8}. Best is trial 0 with value: 1.609437911221773.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=10000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=10000\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=6.585777363287365, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.585777363287365\n",
      "[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.9550303701289281, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.9550303701289281\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.9550303701289281, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.9550303701289281\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.9550303701289281, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.9550303701289281\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.9550303701289281, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.9550303701289281\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n",
      "[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.9550303701289281, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.9550303701289281\n",
      "[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:15,149]\u001b[0m Trial 5 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.1051054125581836, 'num_leaves': 960, 'max_depth': 8, 'min_data_in_leaf': 2700, 'lambda_l1': 90, 'lambda_l2': 30, 'min_gain_to_split': 0.9550303701289281, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.6000000000000001}. Best is trial 0 with value: 1.609437911221773.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.2625809041177, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.2625809041177\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.2625809041177, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.2625809041177\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.2625809041177, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.2625809041177\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.2625809041177, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.2625809041177\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:15,807]\u001b[0m Trial 6 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2506222837477955, 'num_leaves': 640, 'max_depth': 8, 'min_data_in_leaf': 9400, 'lambda_l1': 55, 'lambda_l2': 50, 'min_gain_to_split': 8.2625809041177, 'bagging_fraction': 0.6000000000000001, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 0 with value: 1.609437911221773.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n",
      "[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.2625809041177, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.2625809041177\n",
      "[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.727260255007703, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.727260255007703\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.727260255007703, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.727260255007703\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.727260255007703, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.727260255007703\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.727260255007703, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.727260255007703\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700\n",
      "[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=9.727260255007703, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.727260255007703\n",
      "[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:16,477]\u001b[0m Trial 7 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.21923124481529715, 'num_leaves': 2340, 'max_depth': 9, 'min_data_in_leaf': 6700, 'lambda_l1': 30, 'lambda_l2': 55, 'min_gain_to_split': 9.727260255007703, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.2}. Best is trial 0 with value: 1.609437911221773.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.043400963461695, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.043400963461695\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.043400963461695, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.043400963461695\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.043400963461695, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.043400963461695\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.043400963461695, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.043400963461695\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:17,132]\u001b[0m Trial 8 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.16179953214806123, 'num_leaves': 1700, 'max_depth': 10, 'min_data_in_leaf': 8800, 'lambda_l1': 45, 'lambda_l2': 25, 'min_gain_to_split': 5.043400963461695, 'bagging_fraction': 0.30000000000000004, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 0 with value: 1.609437911221773.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800\n",
      "[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] min_gain_to_split is set=5.043400963461695, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.043400963461695\n",
      "[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7000\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.626877221440285, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.626877221440285\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7000\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.626877221440285, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.626877221440285\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7000\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.626877221440285, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.626877221440285\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7000\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.626877221440285, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.626877221440285\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=7000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7000\n",
      "[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.626877221440285, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.626877221440285\n",
      "[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:17,835]\u001b[0m Trial 9 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.293301936909354, 'num_leaves': 1960, 'max_depth': 7, 'min_data_in_leaf': 7000, 'lambda_l1': 75, 'lambda_l2': 5, 'min_gain_to_split': 12.626877221440285, 'bagging_fraction': 0.4, 'bagging_freq': 1, 'feature_fraction': 0.9}. Best is trial 0 with value: 1.609437911221773.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.732523983335843, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.732523983335843\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.732523983335843, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.732523983335843\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.732523983335843, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.732523983335843\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.732523983335843, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.732523983335843\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n",
      "[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=11.732523983335843, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.732523983335843\n",
      "[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:25,319]\u001b[0m Trial 10 finished with value: 0.8034751177106747 and parameters: {'n_estimators': 10000, 'learning_rate': 0.21747632618002263, 'num_leaves': 40, 'max_depth': 3, 'min_data_in_leaf': 700, 'lambda_l1': 5, 'lambda_l2': 90, 'min_gain_to_split': 11.732523983335843, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 10 with value: 0.8034751177106747.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.556571048383471, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.556571048383471\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.556571048383471, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.556571048383471\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.556571048383471, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.556571048383471\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.556571048383471, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.556571048383471\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.556571048383471, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.556571048383471\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:31,533]\u001b[0m Trial 11 finished with value: 0.7892092976255196 and parameters: {'n_estimators': 10000, 'learning_rate': 0.21523203809422106, 'num_leaves': 60, 'max_depth': 3, 'min_data_in_leaf': 300, 'lambda_l1': 0, 'lambda_l2': 100, 'min_gain_to_split': 12.556571048383471, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 11 with value: 0.7892092976255196.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.005928419504684, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.005928419504684\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.005928419504684, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.005928419504684\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.005928419504684, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.005928419504684\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.005928419504684, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.005928419504684\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n",
      "[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=12.005928419504684, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.005928419504684\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:36,406]\u001b[0m Trial 12 finished with value: 0.7852675308651872 and parameters: {'n_estimators': 10000, 'learning_rate': 0.210011004747083, 'num_leaves': 80, 'max_depth': 3, 'min_data_in_leaf': 300, 'lambda_l1': 0, 'lambda_l2': 95, 'min_gain_to_split': 12.005928419504684, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 12 with value: 0.7852675308651872.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.917015131216004, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.917015131216004\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.917015131216004, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.917015131216004\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.917015131216004, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.917015131216004\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.917015131216004, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.917015131216004\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.917015131216004, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.917015131216004\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:39,284]\u001b[0m Trial 13 finished with value: 0.7815119561815064 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2766527802522418, 'num_leaves': 140, 'max_depth': 3, 'min_data_in_leaf': 200, 'lambda_l1': 0, 'lambda_l2': 100, 'min_gain_to_split': 10.917015131216004, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 13 with value: 0.7815119561815064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.987895092323296, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.987895092323296\n",
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.987895092323296, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.987895092323296\n",
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.987895092323296, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.987895092323296\n",
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.987895092323296, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.987895092323296\n",
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000\n",
      "[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.987895092323296, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.987895092323296\n",
      "[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:42,449]\u001b[0m Trial 14 finished with value: 0.9450496687163978 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2993169740561784, 'num_leaves': 2740, 'max_depth': 5, 'min_data_in_leaf': 2000, 'lambda_l1': 25, 'lambda_l2': 80, 'min_gain_to_split': 10.987895092323296, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.4}. Best is trial 13 with value: 0.7815119561815064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.30909767936993, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.30909767936993\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.30909767936993, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.30909767936993\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.30909767936993, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.30909767936993\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.30909767936993, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.30909767936993\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:43,137]\u001b[0m Trial 15 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2573906444588714, 'num_leaves': 260, 'max_depth': 5, 'min_data_in_leaf': 3900, 'lambda_l1': 15, 'lambda_l2': 75, 'min_gain_to_split': 10.30909767936993, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 13 with value: 0.7815119561815064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.30909767936993, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.30909767936993\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.387850913134156, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.387850913134156\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.387850913134156, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.387850913134156\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.387850913134156, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.387850913134156\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.387850913134156, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.387850913134156\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=7.387850913134156, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.387850913134156\n",
      "[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:47,869]\u001b[0m Trial 16 finished with value: 0.9367558826695058 and parameters: {'n_estimators': 10000, 'learning_rate': 0.11469663494381871, 'num_leaves': 400, 'max_depth': 4, 'min_data_in_leaf': 1600, 'lambda_l1': 40, 'lambda_l2': 100, 'min_gain_to_split': 7.387850913134156, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 13 with value: 0.7815119561815064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.635333717939144, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.635333717939144\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.635333717939144, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.635333717939144\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.635333717939144, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.635333717939144\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.635333717939144, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.635333717939144\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:48,624]\u001b[0m Trial 17 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2646352209221736, 'num_leaves': 1380, 'max_depth': 6, 'min_data_in_leaf': 3400, 'lambda_l1': 15, 'lambda_l2': 75, 'min_gain_to_split': 14.635333717939144, 'bagging_fraction': 0.7, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 13 with value: 0.7815119561815064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400\n",
      "[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] min_gain_to_split is set=14.635333717939144, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.635333717939144\n",
      "[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.3187671992392609, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.3187671992392609\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.3187671992392609, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.3187671992392609\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.3187671992392609, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.3187671992392609\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.3187671992392609, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.3187671992392609\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300\n",
      "[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85\n",
      "[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.3187671992392609, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.3187671992392609\n",
      "[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:53,418]\u001b[0m Trial 18 finished with value: 0.8755070566020764 and parameters: {'n_estimators': 10000, 'learning_rate': 0.18600228518912734, 'num_leaves': 360, 'max_depth': 3, 'min_data_in_leaf': 1300, 'lambda_l1': 35, 'lambda_l2': 85, 'min_gain_to_split': 0.3187671992392609, 'bagging_fraction': 0.8, 'bagging_freq': 1, 'feature_fraction': 0.30000000000000004}. Best is trial 13 with value: 0.7815119561815064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.699512534175337, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.699512534175337\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.699512534175337, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.699512534175337\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.699512534175337, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.699512534175337\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.699512534175337, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.699512534175337\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-06 15:35:54,376]\u001b[0m Trial 19 finished with value: 1.609437911221773 and parameters: {'n_estimators': 10000, 'learning_rate': 0.11920994950442164, 'num_leaves': 1200, 'max_depth': 4, 'min_data_in_leaf': 5700, 'lambda_l1': 0, 'lambda_l2': 65, 'min_gain_to_split': 8.699512534175337, 'bagging_fraction': 0.9, 'bagging_freq': 1, 'feature_fraction': 0.5}. Best is trial 13 with value: 0.7815119561815064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700\n",
      "[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=8.699512534175337, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.699512534175337\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n"
     ]
    }
   ],
   "source": [
    "#perform hyperameter tuning\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\n",
    "func = lambda trial: objective(trial, X, y)\n",
    "study.optimize(func, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBest value (rmse): 0.78151\n",
      "\tBest params:\n",
      "\t\tn_estimators: 10000\n",
      "\t\tlearning_rate: 0.2766527802522418\n",
      "\t\tnum_leaves: 140\n",
      "\t\tmax_depth: 3\n",
      "\t\tmin_data_in_leaf: 200\n",
      "\t\tlambda_l1: 0\n",
      "\t\tlambda_l2: 100\n",
      "\t\tmin_gain_to_split: 10.917015131216004\n",
      "\t\tbagging_fraction: 0.9\n",
      "\t\tbagging_freq: 1\n",
      "\t\tfeature_fraction: 0.4\n"
     ]
    }
   ],
   "source": [
    "# print best parameters\n",
    "print(f\"\\tBest value (rmse): {study.best_value:.5f}\")\n",
    "print(f\"\\tBest params:\")\n",
    "\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"\\t\\t{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200\n",
      "[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] min_gain_to_split is set=10.917015131216004, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.917015131216004\n",
      "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9, bagging_freq=1, class_weight='balanced',\n",
       "               feature_fraction=0.4, lambda_l1=0, lambda_l2=100,\n",
       "               learning_rate=0.2766527802522418, max_depth=3,\n",
       "               min_data_in_leaf=200, min_gain_to_split=10.917015131216004,\n",
       "               n_estimators=10000, num_leaves=140, objective='multiclass')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a classifer with tuned values\n",
    "tuned_clf = lgbm.LGBMClassifier(objective=\"multiclass\", class_weight='balanced', **params)\n",
    "tuned_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tuned_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model accuracy score: 0.6872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 15:36:11.253277: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fd402edea00>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build tensorflow nn classifier\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(54, activation='relu', input_shape=(54,)),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "  ])\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/12/06 15:36:11 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd0ccf70b194240b8a1be23e64bb48466', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "2021-12-06 15:36:11.502824: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-06 15:36:11.502849: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-06 15:36:11.504497: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-06 15:36:11.743666: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  3/154 [..............................] - ETA: 6s - loss: 6351.2533 - accuracy: 0.0489  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0144s). Check your callbacks.\n",
      "104/154 [===================>..........] - ETA: 0s - loss: 851.7274 - accuracy: 0.2394 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 15:36:12.563723: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2021-12-06 15:36:12.563741: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2021-12-06 15:36:12.570300: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2021-12-06 15:36:12.581698: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2021-12-06 15:36:12.610796: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/tmpvhrm851i/train/plugins/profile/2021_12_06_15_36_12\n",
      "2021-12-06 15:36:12.612622: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to /var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/tmpvhrm851i/train/plugins/profile/2021_12_06_15_36_12/Chris-MBPro.local.trace.json.gz\n",
      "2021-12-06 15:36:12.639976: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: /var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/tmpvhrm851i/train/plugins/profile/2021_12_06_15_36_12\n",
      "2021-12-06 15:36:12.640382: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to /var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/tmpvhrm851i/train/plugins/profile/2021_12_06_15_36_12/Chris-MBPro.local.memory_profile.json.gz\n",
      "2021-12-06 15:36:12.642694: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: /var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/tmpvhrm851i/train/plugins/profile/2021_12_06_15_36_12Dumped tool data for xplane.pb to /var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/tmpvhrm851i/train/plugins/profile/2021_12_06_15_36_12/Chris-MBPro.local.xplane.pb\n",
      "Dumped tool data for overview_page.pb to /var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/tmpvhrm851i/train/plugins/profile/2021_12_06_15_36_12/Chris-MBPro.local.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to /var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/tmpvhrm851i/train/plugins/profile/2021_12_06_15_36_12/Chris-MBPro.local.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to /var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/tmpvhrm851i/train/plugins/profile/2021_12_06_15_36_12/Chris-MBPro.local.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to /var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/tmpvhrm851i/train/plugins/profile/2021_12_06_15_36_12/Chris-MBPro.local.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 1s 2ms/step - loss: 631.2017 - accuracy: 0.2793\n",
      "Epoch 2/100\n",
      "154/154 [==============================] - 0s 961us/step - loss: 1.5575 - accuracy: 0.4306\n",
      "Epoch 3/100\n",
      "154/154 [==============================] - 0s 883us/step - loss: 1.4757 - accuracy: 0.4229\n",
      "Epoch 4/100\n",
      "154/154 [==============================] - 0s 685us/step - loss: 1.4271 - accuracy: 0.4384\n",
      "Epoch 5/100\n",
      "154/154 [==============================] - 0s 676us/step - loss: 1.4063 - accuracy: 0.4301\n",
      "Epoch 6/100\n",
      "154/154 [==============================] - 0s 671us/step - loss: 1.4109 - accuracy: 0.4360\n",
      "Epoch 7/100\n",
      "154/154 [==============================] - 0s 677us/step - loss: 1.3804 - accuracy: 0.4321\n",
      "Epoch 8/100\n",
      "154/154 [==============================] - 0s 671us/step - loss: 1.3795 - accuracy: 0.4290\n",
      "Epoch 9/100\n",
      "154/154 [==============================] - 0s 684us/step - loss: 1.3802 - accuracy: 0.4264\n",
      "Epoch 10/100\n",
      "154/154 [==============================] - 0s 695us/step - loss: 1.3604 - accuracy: 0.4354\n",
      "Epoch 11/100\n",
      "154/154 [==============================] - 0s 653us/step - loss: 1.3773 - accuracy: 0.4289\n",
      "Epoch 12/100\n",
      "154/154 [==============================] - 0s 647us/step - loss: 1.3647 - accuracy: 0.4296\n",
      "Epoch 13/100\n",
      "154/154 [==============================] - 0s 680us/step - loss: 1.3754 - accuracy: 0.4288\n",
      "Epoch 14/100\n",
      "154/154 [==============================] - 0s 670us/step - loss: 1.3584 - accuracy: 0.4404\n",
      "Epoch 15/100\n",
      "154/154 [==============================] - 0s 670us/step - loss: 1.3750 - accuracy: 0.4277\n",
      "Epoch 16/100\n",
      "154/154 [==============================] - 0s 694us/step - loss: 1.3743 - accuracy: 0.4312\n",
      "Epoch 17/100\n",
      "154/154 [==============================] - 0s 676us/step - loss: 1.3824 - accuracy: 0.4231\n",
      "Epoch 18/100\n",
      "154/154 [==============================] - 0s 701us/step - loss: 1.3677 - accuracy: 0.4357\n",
      "Epoch 19/100\n",
      "154/154 [==============================] - 0s 645us/step - loss: 1.3583 - accuracy: 0.4376\n",
      "Epoch 20/100\n",
      "154/154 [==============================] - 0s 635us/step - loss: 1.3720 - accuracy: 0.4324\n",
      "Epoch 21/100\n",
      "154/154 [==============================] - 0s 624us/step - loss: 1.3608 - accuracy: 0.4401\n",
      "Epoch 22/100\n",
      "154/154 [==============================] - 0s 620us/step - loss: 1.3606 - accuracy: 0.4337\n",
      "Epoch 23/100\n",
      "154/154 [==============================] - 0s 612us/step - loss: 1.3812 - accuracy: 0.4249\n",
      "Epoch 24/100\n",
      "154/154 [==============================] - 0s 701us/step - loss: 1.3818 - accuracy: 0.4193\n",
      "Epoch 25/100\n",
      "154/154 [==============================] - 0s 677us/step - loss: 1.3668 - accuracy: 0.4346\n",
      "Epoch 26/100\n",
      "154/154 [==============================] - 0s 622us/step - loss: 1.3688 - accuracy: 0.4317\n",
      "Epoch 27/100\n",
      "154/154 [==============================] - 0s 675us/step - loss: 1.3718 - accuracy: 0.4319\n",
      "Epoch 28/100\n",
      "154/154 [==============================] - 0s 633us/step - loss: 1.3718 - accuracy: 0.4302\n",
      "Epoch 29/100\n",
      "154/154 [==============================] - 0s 606us/step - loss: 1.3715 - accuracy: 0.4307\n",
      "Epoch 30/100\n",
      "154/154 [==============================] - 0s 678us/step - loss: 1.3736 - accuracy: 0.4341\n",
      "Epoch 31/100\n",
      "154/154 [==============================] - 0s 636us/step - loss: 1.3679 - accuracy: 0.4303\n",
      "Epoch 32/100\n",
      "154/154 [==============================] - 0s 639us/step - loss: 1.3717 - accuracy: 0.4299\n",
      "Epoch 33/100\n",
      "154/154 [==============================] - 0s 636us/step - loss: 1.3654 - accuracy: 0.4294\n",
      "Epoch 34/100\n",
      "154/154 [==============================] - 0s 617us/step - loss: 1.3700 - accuracy: 0.4325\n",
      "Epoch 35/100\n",
      "154/154 [==============================] - 0s 615us/step - loss: 1.3660 - accuracy: 0.4332\n",
      "Epoch 36/100\n",
      "154/154 [==============================] - 0s 617us/step - loss: 1.3711 - accuracy: 0.4297\n",
      "Epoch 37/100\n",
      "154/154 [==============================] - 0s 605us/step - loss: 1.3814 - accuracy: 0.4223\n",
      "Epoch 38/100\n",
      "154/154 [==============================] - 0s 612us/step - loss: 1.3673 - accuracy: 0.4240\n",
      "Epoch 39/100\n",
      "154/154 [==============================] - 0s 607us/step - loss: 1.3772 - accuracy: 0.4281\n",
      "Epoch 40/100\n",
      "154/154 [==============================] - 0s 615us/step - loss: 1.3615 - accuracy: 0.4382\n",
      "Epoch 41/100\n",
      "154/154 [==============================] - 0s 637us/step - loss: 1.3791 - accuracy: 0.4273\n",
      "Epoch 42/100\n",
      "154/154 [==============================] - 0s 637us/step - loss: 1.3796 - accuracy: 0.4273\n",
      "Epoch 43/100\n",
      "154/154 [==============================] - 0s 621us/step - loss: 1.3719 - accuracy: 0.4321\n",
      "Epoch 44/100\n",
      "154/154 [==============================] - 0s 618us/step - loss: 1.3576 - accuracy: 0.4316\n",
      "Epoch 45/100\n",
      "154/154 [==============================] - 0s 640us/step - loss: 1.3735 - accuracy: 0.4258\n",
      "Epoch 46/100\n",
      "154/154 [==============================] - 0s 616us/step - loss: 1.3741 - accuracy: 0.4268\n",
      "Epoch 47/100\n",
      "154/154 [==============================] - 0s 632us/step - loss: 1.3691 - accuracy: 0.4388\n",
      "Epoch 48/100\n",
      "154/154 [==============================] - 0s 633us/step - loss: 1.3717 - accuracy: 0.4319\n",
      "Epoch 49/100\n",
      "154/154 [==============================] - 0s 674us/step - loss: 1.3615 - accuracy: 0.4281\n",
      "Epoch 50/100\n",
      "154/154 [==============================] - 0s 647us/step - loss: 1.3714 - accuracy: 0.4290\n",
      "Epoch 51/100\n",
      "154/154 [==============================] - 0s 621us/step - loss: 1.3731 - accuracy: 0.4336\n",
      "Epoch 52/100\n",
      "154/154 [==============================] - 0s 639us/step - loss: 1.3768 - accuracy: 0.4278\n",
      "Epoch 53/100\n",
      "154/154 [==============================] - 0s 608us/step - loss: 1.3623 - accuracy: 0.4386\n",
      "Epoch 54/100\n",
      "154/154 [==============================] - 0s 616us/step - loss: 1.3619 - accuracy: 0.4408\n",
      "Epoch 55/100\n",
      "154/154 [==============================] - 0s 630us/step - loss: 1.3793 - accuracy: 0.4257\n",
      "Epoch 56/100\n",
      "154/154 [==============================] - 0s 611us/step - loss: 1.3739 - accuracy: 0.4334\n",
      "Epoch 57/100\n",
      "154/154 [==============================] - 0s 642us/step - loss: 1.3761 - accuracy: 0.4281\n",
      "Epoch 58/100\n",
      "154/154 [==============================] - 0s 623us/step - loss: 1.3577 - accuracy: 0.4354\n",
      "Epoch 59/100\n",
      "154/154 [==============================] - 0s 620us/step - loss: 1.3555 - accuracy: 0.4449\n",
      "Epoch 60/100\n",
      "154/154 [==============================] - 0s 621us/step - loss: 1.3778 - accuracy: 0.4260\n",
      "Epoch 61/100\n",
      "154/154 [==============================] - 0s 605us/step - loss: 1.3645 - accuracy: 0.4341\n",
      "Epoch 62/100\n",
      "154/154 [==============================] - 0s 614us/step - loss: 1.3799 - accuracy: 0.4297\n",
      "Epoch 63/100\n",
      "154/154 [==============================] - 0s 626us/step - loss: 1.3691 - accuracy: 0.4280\n",
      "Epoch 64/100\n",
      "154/154 [==============================] - 0s 635us/step - loss: 1.3772 - accuracy: 0.4302\n",
      "Epoch 65/100\n",
      "154/154 [==============================] - 0s 643us/step - loss: 1.3717 - accuracy: 0.4220\n",
      "Epoch 66/100\n",
      "154/154 [==============================] - 0s 697us/step - loss: 1.3763 - accuracy: 0.4270\n",
      "Epoch 67/100\n",
      "154/154 [==============================] - 0s 658us/step - loss: 1.3736 - accuracy: 0.4313\n",
      "Epoch 68/100\n",
      "154/154 [==============================] - 0s 631us/step - loss: 1.3663 - accuracy: 0.4404\n",
      "Epoch 69/100\n",
      "154/154 [==============================] - 0s 624us/step - loss: 1.3615 - accuracy: 0.4402\n",
      "Epoch 70/100\n",
      "154/154 [==============================] - 0s 626us/step - loss: 1.3728 - accuracy: 0.4323\n",
      "Epoch 71/100\n",
      "154/154 [==============================] - 0s 637us/step - loss: 1.3745 - accuracy: 0.4210\n",
      "Epoch 72/100\n",
      "154/154 [==============================] - 0s 620us/step - loss: 1.3686 - accuracy: 0.4301\n",
      "Epoch 73/100\n",
      "154/154 [==============================] - 0s 622us/step - loss: 1.3723 - accuracy: 0.4253\n",
      "Epoch 74/100\n",
      "154/154 [==============================] - 0s 621us/step - loss: 1.3761 - accuracy: 0.4310\n",
      "Epoch 75/100\n",
      "154/154 [==============================] - 0s 612us/step - loss: 1.3615 - accuracy: 0.4378\n",
      "Epoch 76/100\n",
      "154/154 [==============================] - 0s 608us/step - loss: 1.3815 - accuracy: 0.4299\n",
      "Epoch 77/100\n",
      "154/154 [==============================] - 0s 614us/step - loss: 1.3608 - accuracy: 0.4381\n",
      "Epoch 78/100\n",
      "154/154 [==============================] - 0s 689us/step - loss: 1.3716 - accuracy: 0.4359\n",
      "Epoch 79/100\n",
      "154/154 [==============================] - 0s 669us/step - loss: 1.3660 - accuracy: 0.4313\n",
      "Epoch 80/100\n",
      "154/154 [==============================] - 0s 789us/step - loss: 1.3792 - accuracy: 0.4273\n",
      "Epoch 81/100\n",
      "154/154 [==============================] - 0s 665us/step - loss: 1.3726 - accuracy: 0.4339\n",
      "Epoch 82/100\n",
      "154/154 [==============================] - 0s 646us/step - loss: 1.3708 - accuracy: 0.4332\n",
      "Epoch 83/100\n",
      "154/154 [==============================] - 0s 647us/step - loss: 1.3665 - accuracy: 0.4375\n",
      "Epoch 84/100\n",
      "154/154 [==============================] - 0s 651us/step - loss: 1.3649 - accuracy: 0.4317\n",
      "Epoch 85/100\n",
      "154/154 [==============================] - 0s 738us/step - loss: 1.3677 - accuracy: 0.4368\n",
      "Epoch 86/100\n",
      "154/154 [==============================] - 0s 691us/step - loss: 1.3804 - accuracy: 0.4252\n",
      "Epoch 87/100\n",
      "154/154 [==============================] - 0s 806us/step - loss: 1.3717 - accuracy: 0.4349\n",
      "Epoch 88/100\n",
      "154/154 [==============================] - 0s 696us/step - loss: 1.3639 - accuracy: 0.4359\n",
      "Epoch 89/100\n",
      "154/154 [==============================] - 0s 683us/step - loss: 1.3729 - accuracy: 0.4267\n",
      "Epoch 90/100\n",
      "154/154 [==============================] - 0s 635us/step - loss: 1.3568 - accuracy: 0.4394\n",
      "Epoch 91/100\n",
      "154/154 [==============================] - 0s 615us/step - loss: 1.3737 - accuracy: 0.4316\n",
      "Epoch 92/100\n",
      "154/154 [==============================] - 0s 627us/step - loss: 1.3588 - accuracy: 0.4362\n",
      "Epoch 93/100\n",
      "154/154 [==============================] - 0s 664us/step - loss: 1.3656 - accuracy: 0.4366\n",
      "Epoch 94/100\n",
      "154/154 [==============================] - 0s 828us/step - loss: 1.3671 - accuracy: 0.4288\n",
      "Epoch 95/100\n",
      "154/154 [==============================] - 0s 833us/step - loss: 1.3684 - accuracy: 0.4316\n",
      "Epoch 96/100\n",
      "154/154 [==============================] - 0s 698us/step - loss: 1.3641 - accuracy: 0.4379\n",
      "Epoch 97/100\n",
      "154/154 [==============================] - 0s 617us/step - loss: 1.3567 - accuracy: 0.4367\n",
      "Epoch 98/100\n",
      "154/154 [==============================] - 0s 601us/step - loss: 1.3754 - accuracy: 0.4234\n",
      "Epoch 99/100\n",
      "154/154 [==============================] - 0s 630us/step - loss: 1.3601 - accuracy: 0.4374\n",
      "Epoch 100/100\n",
      "154/154 [==============================] - 0s 676us/step - loss: 1.3635 - accuracy: 0.4306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 15:36:23.800439: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/2f/rkv3v49j0b7_2hx0f3fxytf09v2bcg/T/tmpei8zxc6b/model/data/model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd4026101c0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, batch_size=50, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 490us/step - loss: 2.3683 - accuracy: 0.4000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.368317127227783, 0.4000000059604645]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sad face for bad performance\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shap analysis to inspect features\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x684 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X, show=False)\n",
    "plt.savefig('../images/shap_values.png', facecolor='w', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving the model\n",
    "filename = '../models/best_model.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "with open('../models/best_model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>payment_note_date</th>\n",
       "      <th>payment_note_amount</th>\n",
       "      <th>financials_date</th>\n",
       "      <th>financials_date-1</th>\n",
       "      <th>financials_date-2</th>\n",
       "      <th>financials_date-3</th>\n",
       "      <th>financials_date-4</th>\n",
       "      <th>revenue</th>\n",
       "      <th>revenue-1</th>\n",
       "      <th>...</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>profit_margin-1</th>\n",
       "      <th>profit_margin-2</th>\n",
       "      <th>profit_margin-3</th>\n",
       "      <th>profit_margin-4</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>cash_ratio-1</th>\n",
       "      <th>cash_ratio-2</th>\n",
       "      <th>cash_ratio-3</th>\n",
       "      <th>cash_ratio-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec-17</td>\n",
       "      <td>Dec-16</td>\n",
       "      <td>Dec-15</td>\n",
       "      <td>Dec-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4617</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>112.9</td>\n",
       "      <td>74.9</td>\n",
       "      <td>46.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec-17</td>\n",
       "      <td>Dec-16</td>\n",
       "      <td>Dec-15</td>\n",
       "      <td>Dec-14</td>\n",
       "      <td>Dec-13</td>\n",
       "      <td>5446</td>\n",
       "      <td>5529.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>30.2</td>\n",
       "      <td>35.2</td>\n",
       "      <td>44.9</td>\n",
       "      <td>48.6</td>\n",
       "      <td>39.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr-18</td>\n",
       "      <td>Apr-17</td>\n",
       "      <td>Apr-16</td>\n",
       "      <td>Apr-15</td>\n",
       "      <td>Apr-14</td>\n",
       "      <td>8087</td>\n",
       "      <td>6872.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>273.9</td>\n",
       "      <td>239.3</td>\n",
       "      <td>296.9</td>\n",
       "      <td>631.8</td>\n",
       "      <td>568.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec-17</td>\n",
       "      <td>Dec-16</td>\n",
       "      <td>Dec-15</td>\n",
       "      <td>Dec-14</td>\n",
       "      <td>Dec-13</td>\n",
       "      <td>9507</td>\n",
       "      <td>7449.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>115.6</td>\n",
       "      <td>89.9</td>\n",
       "      <td>102.5</td>\n",
       "      <td>80.8</td>\n",
       "      <td>86.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jun-18</td>\n",
       "      <td>Jun-17</td>\n",
       "      <td>Jun-16</td>\n",
       "      <td>Jun-15</td>\n",
       "      <td>Jun-14</td>\n",
       "      <td>45618</td>\n",
       "      <td>48085.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2</td>\n",
       "      <td>9.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>14.6</td>\n",
       "      <td>190.2</td>\n",
       "      <td>181.1</td>\n",
       "      <td>186.9</td>\n",
       "      <td>151.6</td>\n",
       "      <td>158.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>13701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dec-17</td>\n",
       "      <td>Dec-16</td>\n",
       "      <td>Dec-15</td>\n",
       "      <td>Dec-14</td>\n",
       "      <td>Dec-13</td>\n",
       "      <td>23235</td>\n",
       "      <td>20661.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>163.9</td>\n",
       "      <td>174.0</td>\n",
       "      <td>155.6</td>\n",
       "      <td>114.6</td>\n",
       "      <td>183.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>13702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Apr-18</td>\n",
       "      <td>Apr-17</td>\n",
       "      <td>Apr-16</td>\n",
       "      <td>Apr-15</td>\n",
       "      <td>Apr-14</td>\n",
       "      <td>18259</td>\n",
       "      <td>14507.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>165.2</td>\n",
       "      <td>152.8</td>\n",
       "      <td>124.1</td>\n",
       "      <td>110.2</td>\n",
       "      <td>87.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>13703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aug-18</td>\n",
       "      <td>Aug-17</td>\n",
       "      <td>Aug-16</td>\n",
       "      <td>Aug-15</td>\n",
       "      <td>Aug-14</td>\n",
       "      <td>14527</td>\n",
       "      <td>9733.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>153.7</td>\n",
       "      <td>151.0</td>\n",
       "      <td>122.4</td>\n",
       "      <td>91.1</td>\n",
       "      <td>115.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>13704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aug-17</td>\n",
       "      <td>Aug-16</td>\n",
       "      <td>Aug-15</td>\n",
       "      <td>Aug-14</td>\n",
       "      <td>Aug-13</td>\n",
       "      <td>5657</td>\n",
       "      <td>4861.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>15.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>291.7</td>\n",
       "      <td>286.6</td>\n",
       "      <td>244.7</td>\n",
       "      <td>176.9</td>\n",
       "      <td>81.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>13705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Dec-17</td>\n",
       "      <td>Dec-16</td>\n",
       "      <td>Dec-15</td>\n",
       "      <td>Dec-14</td>\n",
       "      <td>Dec-13</td>\n",
       "      <td>17258</td>\n",
       "      <td>15800.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.5</td>\n",
       "      <td>25.7</td>\n",
       "      <td>22.3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>414.7</td>\n",
       "      <td>439.8</td>\n",
       "      <td>809.7</td>\n",
       "      <td>800.9</td>\n",
       "      <td>625.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2741 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      company_id payment_note_date  payment_note_amount financials_date  \\\n",
       "0          10965               NaN                  NaN          Dec-17   \n",
       "1          10966               NaN                  NaN          Dec-17   \n",
       "2          10967               NaN                  NaN          Apr-18   \n",
       "3          10968               NaN                  NaN          Dec-17   \n",
       "4          10969               NaN                  0.0          Jun-18   \n",
       "...          ...               ...                  ...             ...   \n",
       "2736       13701               NaN                  0.0          Dec-17   \n",
       "2737       13702               NaN                  0.0          Apr-18   \n",
       "2738       13703               NaN                  NaN          Aug-18   \n",
       "2739       13704               NaN                  NaN          Aug-17   \n",
       "2740       13705               NaN                  0.0          Dec-17   \n",
       "\n",
       "     financials_date-1 financials_date-2 financials_date-3 financials_date-4  \\\n",
       "0               Dec-16            Dec-15            Dec-14               NaN   \n",
       "1               Dec-16            Dec-15            Dec-14            Dec-13   \n",
       "2               Apr-17            Apr-16            Apr-15            Apr-14   \n",
       "3               Dec-16            Dec-15            Dec-14            Dec-13   \n",
       "4               Jun-17            Jun-16            Jun-15            Jun-14   \n",
       "...                ...               ...               ...               ...   \n",
       "2736            Dec-16            Dec-15            Dec-14            Dec-13   \n",
       "2737            Apr-17            Apr-16            Apr-15            Apr-14   \n",
       "2738            Aug-17            Aug-16            Aug-15            Aug-14   \n",
       "2739            Aug-16            Aug-15            Aug-14            Aug-13   \n",
       "2740            Dec-16            Dec-15            Dec-14            Dec-13   \n",
       "\n",
       "      revenue  revenue-1  ...  profit_margin  profit_margin-1  \\\n",
       "0        4617     3760.0  ...           23.1              9.5   \n",
       "1        5446     5529.0  ...            1.7              0.8   \n",
       "2        8087     6872.0  ...           20.0             11.3   \n",
       "3        9507     7449.0  ...           25.9             23.1   \n",
       "4       45618    48085.0  ...           13.2              9.8   \n",
       "...       ...        ...  ...            ...              ...   \n",
       "2736    23235    20661.0  ...            2.3              1.6   \n",
       "2737    18259    14507.0  ...           11.9              2.2   \n",
       "2738    14527     9733.0  ...            0.8              3.7   \n",
       "2739     5657     4861.0  ...           14.3             12.2   \n",
       "2740    17258    15800.0  ...           24.5             25.7   \n",
       "\n",
       "      profit_margin-2  profit_margin-3  profit_margin-4  cash_ratio  \\\n",
       "0                -0.3              5.1              NaN        48.0   \n",
       "1                 0.3              0.6             -1.3        30.2   \n",
       "2                15.9             21.8             13.4       273.9   \n",
       "3                11.7              5.8             12.5       115.6   \n",
       "4                18.0             10.5             14.6       190.2   \n",
       "...               ...              ...              ...         ...   \n",
       "2736              5.1             -9.4             -8.5       163.9   \n",
       "2737              5.0              2.0              0.6       165.2   \n",
       "2738              4.6              1.4              1.9       153.7   \n",
       "2739             15.9             12.0             10.1       291.7   \n",
       "2740             22.3             33.0             30.9       414.7   \n",
       "\n",
       "      cash_ratio-1  cash_ratio-2  cash_ratio-3  cash_ratio-4  \n",
       "0            112.9          74.9          46.7           NaN  \n",
       "1             35.2          44.9          48.6          39.7  \n",
       "2            239.3         296.9         631.8         568.1  \n",
       "3             89.9         102.5          80.8          86.2  \n",
       "4            181.1         186.9         151.6         158.7  \n",
       "...            ...           ...           ...           ...  \n",
       "2736         174.0         155.6         114.6         183.6  \n",
       "2737         152.8         124.1         110.2          87.2  \n",
       "2738         151.0         122.4          91.1         115.3  \n",
       "2739         286.6         244.7         176.9          81.2  \n",
       "2740         439.8         809.7         800.9         625.6  \n",
       "\n",
       "[2741 rows x 58 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('../data/raw/test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do al cleaning and transformations before prediction\n",
    "def cleaning(data):\n",
    "    for i in range(3, 8):\n",
    "        data.iloc[:, i] = pd.to_datetime(data.iloc[:, i], format=\"%b-%y\")\n",
    "    data['years_data'] = data.iloc[:, 3:8].max(axis=1).dt.year + 1 - data.iloc[:, 3:8].min(axis=1).dt.year\n",
    "    data['has_payment_note'] = np.where(data.payment_note_date.notnull(), 1, 0)\n",
    "    data.drop(columns=['company_id', 'payment_note_date', 'financials_date', 'financials_date-1', 'financials_date-2', 'financials_date-3', 'financials_date-4'], inplace=True)\n",
    "    col = data.pop('has_payment_note')\n",
    "    data.insert(0, 'has_payment_note', col)\n",
    "    col = data.pop('years_data')\n",
    "    data.insert(2, 'years_data', col)\n",
    "    clean_data = data.fillna(0)\n",
    "    return clean_data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_payment_note</th>\n",
       "      <th>payment_note_amount</th>\n",
       "      <th>years_data</th>\n",
       "      <th>revenue</th>\n",
       "      <th>revenue-1</th>\n",
       "      <th>revenue-2</th>\n",
       "      <th>revenue-3</th>\n",
       "      <th>revenue-4</th>\n",
       "      <th>net_sales</th>\n",
       "      <th>net_sales-1</th>\n",
       "      <th>...</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>profit_margin-1</th>\n",
       "      <th>profit_margin-2</th>\n",
       "      <th>profit_margin-3</th>\n",
       "      <th>profit_margin-4</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>cash_ratio-1</th>\n",
       "      <th>cash_ratio-2</th>\n",
       "      <th>cash_ratio-3</th>\n",
       "      <th>cash_ratio-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4617</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>2774.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4081</td>\n",
       "      <td>3645.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>112.9</td>\n",
       "      <td>74.9</td>\n",
       "      <td>46.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5446</td>\n",
       "      <td>5529.0</td>\n",
       "      <td>5732.0</td>\n",
       "      <td>5582.0</td>\n",
       "      <td>5164.0</td>\n",
       "      <td>5510</td>\n",
       "      <td>5239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>30.2</td>\n",
       "      <td>35.2</td>\n",
       "      <td>44.9</td>\n",
       "      <td>48.6</td>\n",
       "      <td>39.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>8087</td>\n",
       "      <td>6872.0</td>\n",
       "      <td>7200.0</td>\n",
       "      <td>6923.0</td>\n",
       "      <td>6845.0</td>\n",
       "      <td>8031</td>\n",
       "      <td>6797.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>273.9</td>\n",
       "      <td>239.3</td>\n",
       "      <td>296.9</td>\n",
       "      <td>631.8</td>\n",
       "      <td>568.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9507</td>\n",
       "      <td>7449.0</td>\n",
       "      <td>4940.0</td>\n",
       "      <td>4478.0</td>\n",
       "      <td>4966.0</td>\n",
       "      <td>8874</td>\n",
       "      <td>7109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>115.6</td>\n",
       "      <td>89.9</td>\n",
       "      <td>102.5</td>\n",
       "      <td>80.8</td>\n",
       "      <td>86.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>45618</td>\n",
       "      <td>48085.0</td>\n",
       "      <td>50221.0</td>\n",
       "      <td>35558.0</td>\n",
       "      <td>30520.0</td>\n",
       "      <td>45304</td>\n",
       "      <td>47484.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.2</td>\n",
       "      <td>9.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>14.6</td>\n",
       "      <td>190.2</td>\n",
       "      <td>181.1</td>\n",
       "      <td>186.9</td>\n",
       "      <td>151.6</td>\n",
       "      <td>158.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>23235</td>\n",
       "      <td>20661.0</td>\n",
       "      <td>19552.0</td>\n",
       "      <td>16269.0</td>\n",
       "      <td>17908.0</td>\n",
       "      <td>22784</td>\n",
       "      <td>20716.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-9.4</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>163.9</td>\n",
       "      <td>174.0</td>\n",
       "      <td>155.6</td>\n",
       "      <td>114.6</td>\n",
       "      <td>183.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>18259</td>\n",
       "      <td>14507.0</td>\n",
       "      <td>15674.0</td>\n",
       "      <td>14150.0</td>\n",
       "      <td>12069.0</td>\n",
       "      <td>18119</td>\n",
       "      <td>14386.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>165.2</td>\n",
       "      <td>152.8</td>\n",
       "      <td>124.1</td>\n",
       "      <td>110.2</td>\n",
       "      <td>87.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>14527</td>\n",
       "      <td>9733.0</td>\n",
       "      <td>10604.0</td>\n",
       "      <td>5181.0</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>14502</td>\n",
       "      <td>9439.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>153.7</td>\n",
       "      <td>151.0</td>\n",
       "      <td>122.4</td>\n",
       "      <td>91.1</td>\n",
       "      <td>115.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5657</td>\n",
       "      <td>4861.0</td>\n",
       "      <td>3910.0</td>\n",
       "      <td>4234.0</td>\n",
       "      <td>4061.0</td>\n",
       "      <td>5533</td>\n",
       "      <td>4707.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.3</td>\n",
       "      <td>12.2</td>\n",
       "      <td>15.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>291.7</td>\n",
       "      <td>286.6</td>\n",
       "      <td>244.7</td>\n",
       "      <td>176.9</td>\n",
       "      <td>81.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>17258</td>\n",
       "      <td>15800.0</td>\n",
       "      <td>12276.0</td>\n",
       "      <td>13161.0</td>\n",
       "      <td>16701.0</td>\n",
       "      <td>17194</td>\n",
       "      <td>15782.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.5</td>\n",
       "      <td>25.7</td>\n",
       "      <td>22.3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>414.7</td>\n",
       "      <td>439.8</td>\n",
       "      <td>809.7</td>\n",
       "      <td>800.9</td>\n",
       "      <td>625.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2741 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      has_payment_note  payment_note_amount  years_data  revenue  revenue-1  \\\n",
       "0                    0                  0.0           4     4617     3760.0   \n",
       "1                    0                  0.0           5     5446     5529.0   \n",
       "2                    0                  0.0           5     8087     6872.0   \n",
       "3                    0                  0.0           5     9507     7449.0   \n",
       "4                    0                  0.0           5    45618    48085.0   \n",
       "...                ...                  ...         ...      ...        ...   \n",
       "2736                 0                  0.0           5    23235    20661.0   \n",
       "2737                 0                  0.0           5    18259    14507.0   \n",
       "2738                 0                  0.0           5    14527     9733.0   \n",
       "2739                 0                  0.0           5     5657     4861.0   \n",
       "2740                 0                  0.0           5    17258    15800.0   \n",
       "\n",
       "      revenue-2  revenue-3  revenue-4  net_sales  net_sales-1  ...  \\\n",
       "0        2774.0     1989.0        0.0       4081       3645.0  ...   \n",
       "1        5732.0     5582.0     5164.0       5510       5239.0  ...   \n",
       "2        7200.0     6923.0     6845.0       8031       6797.0  ...   \n",
       "3        4940.0     4478.0     4966.0       8874       7109.0  ...   \n",
       "4       50221.0    35558.0    30520.0      45304      47484.0  ...   \n",
       "...         ...        ...        ...        ...          ...  ...   \n",
       "2736    19552.0    16269.0    17908.0      22784      20716.0  ...   \n",
       "2737    15674.0    14150.0    12069.0      18119      14386.0  ...   \n",
       "2738    10604.0     5181.0     2890.0      14502       9439.0  ...   \n",
       "2739     3910.0     4234.0     4061.0       5533       4707.0  ...   \n",
       "2740    12276.0    13161.0    16701.0      17194      15782.0  ...   \n",
       "\n",
       "      profit_margin  profit_margin-1  profit_margin-2  profit_margin-3  \\\n",
       "0              23.1              9.5             -0.3              5.1   \n",
       "1               1.7              0.8              0.3              0.6   \n",
       "2              20.0             11.3             15.9             21.8   \n",
       "3              25.9             23.1             11.7              5.8   \n",
       "4              13.2              9.8             18.0             10.5   \n",
       "...             ...              ...              ...              ...   \n",
       "2736            2.3              1.6              5.1             -9.4   \n",
       "2737           11.9              2.2              5.0              2.0   \n",
       "2738            0.8              3.7              4.6              1.4   \n",
       "2739           14.3             12.2             15.9             12.0   \n",
       "2740           24.5             25.7             22.3             33.0   \n",
       "\n",
       "      profit_margin-4  cash_ratio  cash_ratio-1  cash_ratio-2  cash_ratio-3  \\\n",
       "0                 0.0        48.0         112.9          74.9          46.7   \n",
       "1                -1.3        30.2          35.2          44.9          48.6   \n",
       "2                13.4       273.9         239.3         296.9         631.8   \n",
       "3                12.5       115.6          89.9         102.5          80.8   \n",
       "4                14.6       190.2         181.1         186.9         151.6   \n",
       "...               ...         ...           ...           ...           ...   \n",
       "2736             -8.5       163.9         174.0         155.6         114.6   \n",
       "2737              0.6       165.2         152.8         124.1         110.2   \n",
       "2738              1.9       153.7         151.0         122.4          91.1   \n",
       "2739             10.1       291.7         286.6         244.7         176.9   \n",
       "2740             30.9       414.7         439.8         809.7         800.9   \n",
       "\n",
       "      cash_ratio-4  \n",
       "0              0.0  \n",
       "1             39.7  \n",
       "2            568.1  \n",
       "3             86.2  \n",
       "4            158.7  \n",
       "...            ...  \n",
       "2736         183.6  \n",
       "2737          87.2  \n",
       "2738         115.3  \n",
       "2739          81.2  \n",
       "2740         625.6  \n",
       "\n",
       "[2741 rows x 53 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_df = cleaning(test_df.copy())\n",
    "clean_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>payment_note_date</th>\n",
       "      <th>payment_note_amount</th>\n",
       "      <th>financials_date</th>\n",
       "      <th>financials_date-1</th>\n",
       "      <th>financials_date-2</th>\n",
       "      <th>financials_date-3</th>\n",
       "      <th>financials_date-4</th>\n",
       "      <th>revenue</th>\n",
       "      <th>revenue-1</th>\n",
       "      <th>...</th>\n",
       "      <th>profit_margin-1</th>\n",
       "      <th>profit_margin-2</th>\n",
       "      <th>profit_margin-3</th>\n",
       "      <th>profit_margin-4</th>\n",
       "      <th>cash_ratio</th>\n",
       "      <th>cash_ratio-1</th>\n",
       "      <th>cash_ratio-2</th>\n",
       "      <th>cash_ratio-3</th>\n",
       "      <th>cash_ratio-4</th>\n",
       "      <th>Predicted Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec-17</td>\n",
       "      <td>Dec-16</td>\n",
       "      <td>Dec-15</td>\n",
       "      <td>Dec-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4617</td>\n",
       "      <td>3760.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>112.9</td>\n",
       "      <td>74.9</td>\n",
       "      <td>46.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec-17</td>\n",
       "      <td>Dec-16</td>\n",
       "      <td>Dec-15</td>\n",
       "      <td>Dec-14</td>\n",
       "      <td>Dec-13</td>\n",
       "      <td>5446</td>\n",
       "      <td>5529.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>30.2</td>\n",
       "      <td>35.2</td>\n",
       "      <td>44.9</td>\n",
       "      <td>48.6</td>\n",
       "      <td>39.7</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apr-18</td>\n",
       "      <td>Apr-17</td>\n",
       "      <td>Apr-16</td>\n",
       "      <td>Apr-15</td>\n",
       "      <td>Apr-14</td>\n",
       "      <td>8087</td>\n",
       "      <td>6872.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>273.9</td>\n",
       "      <td>239.3</td>\n",
       "      <td>296.9</td>\n",
       "      <td>631.8</td>\n",
       "      <td>568.1</td>\n",
       "      <td>AAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec-17</td>\n",
       "      <td>Dec-16</td>\n",
       "      <td>Dec-15</td>\n",
       "      <td>Dec-14</td>\n",
       "      <td>Dec-13</td>\n",
       "      <td>9507</td>\n",
       "      <td>7449.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>115.6</td>\n",
       "      <td>89.9</td>\n",
       "      <td>102.5</td>\n",
       "      <td>80.8</td>\n",
       "      <td>86.2</td>\n",
       "      <td>AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jun-18</td>\n",
       "      <td>Jun-17</td>\n",
       "      <td>Jun-16</td>\n",
       "      <td>Jun-15</td>\n",
       "      <td>Jun-14</td>\n",
       "      <td>45618</td>\n",
       "      <td>48085.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>14.6</td>\n",
       "      <td>190.2</td>\n",
       "      <td>181.1</td>\n",
       "      <td>186.9</td>\n",
       "      <td>151.6</td>\n",
       "      <td>158.7</td>\n",
       "      <td>AAA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_id payment_note_date  payment_note_amount financials_date  \\\n",
       "0       10965               NaN                  NaN          Dec-17   \n",
       "1       10966               NaN                  NaN          Dec-17   \n",
       "2       10967               NaN                  NaN          Apr-18   \n",
       "3       10968               NaN                  NaN          Dec-17   \n",
       "4       10969               NaN                  0.0          Jun-18   \n",
       "\n",
       "  financials_date-1 financials_date-2 financials_date-3 financials_date-4  \\\n",
       "0            Dec-16            Dec-15            Dec-14               NaN   \n",
       "1            Dec-16            Dec-15            Dec-14            Dec-13   \n",
       "2            Apr-17            Apr-16            Apr-15            Apr-14   \n",
       "3            Dec-16            Dec-15            Dec-14            Dec-13   \n",
       "4            Jun-17            Jun-16            Jun-15            Jun-14   \n",
       "\n",
       "   revenue  revenue-1  ...  profit_margin-1  profit_margin-2  profit_margin-3  \\\n",
       "0     4617     3760.0  ...              9.5             -0.3              5.1   \n",
       "1     5446     5529.0  ...              0.8              0.3              0.6   \n",
       "2     8087     6872.0  ...             11.3             15.9             21.8   \n",
       "3     9507     7449.0  ...             23.1             11.7              5.8   \n",
       "4    45618    48085.0  ...              9.8             18.0             10.5   \n",
       "\n",
       "   profit_margin-4  cash_ratio  cash_ratio-1  cash_ratio-2  cash_ratio-3  \\\n",
       "0              NaN        48.0         112.9          74.9          46.7   \n",
       "1             -1.3        30.2          35.2          44.9          48.6   \n",
       "2             13.4       273.9         239.3         296.9         631.8   \n",
       "3             12.5       115.6          89.9         102.5          80.8   \n",
       "4             14.6       190.2         181.1         186.9         151.6   \n",
       "\n",
       "   cash_ratio-4  Predicted Rating  \n",
       "0           NaN                 A  \n",
       "1          39.7                 A  \n",
       "2         568.1               AAA  \n",
       "3          86.2                AA  \n",
       "4         158.7               AAA  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(clean_test_df)\n",
    "y_pred_decoded = le.inverse_transform(y_pred)\n",
    "test_df['Predicted Rating'] = y_pred_decoded\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('../data/output/test.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "49816d6f974cc66bbd36942491f17829fd413bd109f42d7e0999e6b45e4dcfc1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('22seven': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
